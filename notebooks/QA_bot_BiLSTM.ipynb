{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets transformers pytorch-lightning","metadata":{"id":"_y3r09skrj9-","outputId":"5b4577c1-e5c1-4e8f-9315-33d36e409bca","execution":{"iopub.status.busy":"2022-06-16T16:23:07.210049Z","iopub.execute_input":"2022-06-16T16:23:07.210498Z","iopub.status.idle":"2022-06-16T16:23:18.269487Z","shell.execute_reply.started":"2022-06-16T16:23:07.210462Z","shell.execute_reply":"2022-06-16T16:23:18.268365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport torch\nfrom torch.jit import script, trace\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport csv\nimport random\nimport re\nimport os\nimport unicodedata\nimport codecs\nfrom io import open\nimport itertools\nimport math\n\n\nUSE_CUDA = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if USE_CUDA else \"cpu\")","metadata":{"id":"N3J9ovIHCwx8","execution":{"iopub.status.busy":"2022-06-16T16:23:18.272292Z","iopub.execute_input":"2022-06-16T16:23:18.272785Z","iopub.status.idle":"2022-06-16T16:23:20.050088Z","shell.execute_reply.started":"2022-06-16T16:23:18.272732Z","shell.execute_reply":"2022-06-16T16:23:20.049188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import BertTokenizerFast\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch\nfrom torch import nn\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom torch.nn import functional as F","metadata":{"id":"1uWW3SJymzyj","execution":{"iopub.status.busy":"2022-06-16T16:23:20.051409Z","iopub.execute_input":"2022-06-16T16:23:20.052757Z","iopub.status.idle":"2022-06-16T16:23:28.397315Z","shell.execute_reply.started":"2022-06-16T16:23:20.052704Z","shell.execute_reply":"2022-06-16T16:23:28.396058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create datasets","metadata":{"id":"qlU83w7N3t8U"}},{"cell_type":"code","source":"squadv2 = load_dataset(\"squad_v2\")","metadata":{"id":"8v-3zBuGrd82","outputId":"80f29415-5eb4-43fb-df2d-be7ded0a3be3","execution":{"iopub.status.busy":"2022-06-16T16:23:28.400415Z","iopub.execute_input":"2022-06-16T16:23:28.40142Z","iopub.status.idle":"2022-06-16T16:23:46.922036Z","shell.execute_reply.started":"2022-06-16T16:23:28.401366Z","shell.execute_reply":"2022-06-16T16:23:46.921044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"squadv2 # train and validation sets (we will treat validation set as test set)","metadata":{"id":"n0zC46UA6lTo","outputId":"774f968b-b1a2-4162-eb7b-75bea922b01b","execution":{"iopub.status.busy":"2022-06-16T16:23:46.923311Z","iopub.execute_input":"2022-06-16T16:23:46.923723Z","iopub.status.idle":"2022-06-16T16:23:46.932373Z","shell.execute_reply.started":"2022-06-16T16:23:46.923688Z","shell.execute_reply":"2022-06-16T16:23:46.931132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers.utils.dummy_pt_objects import LayoutLMv2ForQuestionAnswering\n\ndef create_dataset(squad_data, split=None):\n    print(\"FIRST PASS\")\n    contexts = set()\n    for row in tqdm(squad_data):\n        contexts.add(row[\"context\"])\n    \n    if split:\n        contexts = tuple(contexts)\n        n_valid = int(split*len(contexts))\n        splits = [contexts[:n_valid], contexts[n_valid:]]\n    else:\n        splits = [tuple(contexts)]    \n\n    full_data = {s: {\n        'question': [],\n        'context': [],\n        'orig_answer': [],\n        'answer_begin': [],\n        'answer_end': [],\n    } for s in splits}\n\n    print(\"SECOND PASS\")\n    for row in tqdm(squad_data):\n        # Let's ignore all impossible answers for now\n\n        answers_start, answers_text = row['answers'][\"answer_start\"], row[\"answers\"][\"text\"]\n        answers_full = list(set(list(zip(answers_start, answers_text))))\n        for start_idx, answer_text in answers_full:\n            text = row['context']\n            end_idx = start_idx + len(answer_text)\n\n            for key, data in full_data.items():\n                if text in key:\n                    data['question'].append(row['question'])\n                    data['context'].append(text)\n                    data['orig_answer'].append(answer_text)\n                    data['answer_begin'].append(start_idx)\n\n                    # Deal with the problem of 1 or 2 more characters \n                    if text[start_idx:end_idx] == answer_text:\n                        data['answer_end'].append(end_idx)\n                    else:\n                        raise RuntimeError(\"There are only 1 or 2 character shifts in the dataset so this error should never happen\")\n    \n    if len(splits) == 1:\n        return full_data[splits[0]]\n    return full_data[splits[1]], full_data[splits[0]]","metadata":{"id":"_bHeQBRX5_ON","execution":{"iopub.status.busy":"2022-06-16T16:23:46.933701Z","iopub.execute_input":"2022-06-16T16:23:46.934072Z","iopub.status.idle":"2022-06-16T16:23:46.956619Z","shell.execute_reply.started":"2022-06-16T16:23:46.934035Z","shell.execute_reply":"2022-06-16T16:23:46.955838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, valid = create_dataset(squadv2[\"train\"], 0.1)\ntest = create_dataset(squadv2[\"validation\"])","metadata":{"id":"Em0zGBmkneO1","outputId":"dc6a7d54-008e-477a-9526-d6cb82579738","execution":{"iopub.status.busy":"2022-06-16T16:23:46.957589Z","iopub.execute_input":"2022-06-16T16:23:46.958589Z","iopub.status.idle":"2022-06-16T16:24:46.934565Z","shell.execute_reply.started":"2022-06-16T16:23:46.958548Z","shell.execute_reply":"2022-06-16T16:24:46.933355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame(train)\ntrain_df","metadata":{"id":"FxyihdSNDF18","outputId":"fcf6a49f-fe50-4c23-e8c0-46b2e92f1848","execution":{"iopub.status.busy":"2022-06-16T16:24:46.936119Z","iopub.execute_input":"2022-06-16T16:24:46.936432Z","iopub.status.idle":"2022-06-16T16:24:47.047037Z","shell.execute_reply.started":"2022-06-16T16:24:46.936405Z","shell.execute_reply":"2022-06-16T16:24:47.046037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df = pd.DataFrame(valid)\nvalid_df","metadata":{"id":"X8ssuSY2LHKo","outputId":"6ce1f015-c4f5-4ef8-c349-1ff641d52766","execution":{"iopub.status.busy":"2022-06-16T16:24:47.048413Z","iopub.execute_input":"2022-06-16T16:24:47.048721Z","iopub.status.idle":"2022-06-16T16:24:47.072763Z","shell.execute_reply.started":"2022-06-16T16:24:47.048694Z","shell.execute_reply":"2022-06-16T16:24:47.071837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.DataFrame(test)\ntest_df","metadata":{"id":"dGSHAu__LH4h","outputId":"345482fc-7ed0-40fb-8e07-f10f3334dc29","execution":{"iopub.status.busy":"2022-06-16T16:24:47.075268Z","iopub.execute_input":"2022-06-16T16:24:47.075589Z","iopub.status.idle":"2022-06-16T16:24:47.098338Z","shell.execute_reply.started":"2022-06-16T16:24:47.075561Z","shell.execute_reply":"2022-06-16T16:24:47.097237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True, clean_text=True)\n# tokenize\ntrain_tokenizer = tokenizer(train['context'], train['question'],\n                  truncation=True, padding='max_length',\n                  max_length=512, return_tensors='pt')\nvalid_tokenizer = tokenizer(valid['context'], valid['question'],\n                  truncation=True, padding='max_length',\n                  max_length=512, return_tensors='pt')\ntest_tokenizer = tokenizer(test['context'], test['question'],\n                  truncation=True, padding='max_length',\n                  max_length=512, return_tensors='pt')","metadata":{"id":"l1n-8jQYqCvv","execution":{"iopub.status.busy":"2022-06-16T16:24:47.099952Z","iopub.execute_input":"2022-06-16T16:24:47.10087Z","iopub.status.idle":"2022-06-16T16:25:34.537091Z","shell.execute_reply.started":"2022-06-16T16:24:47.100815Z","shell.execute_reply":"2022-06-16T16:25:34.536072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_token_positions(encodings, data):\n    start_positions = []\n    end_positions = []\n\n    count = 0\n    for i in range(len(data['context'])):\n        start_positions.append(encodings.char_to_token(i, data['answer_begin'][i]))\n        end_positions.append(encodings.char_to_token(i, data['answer_end'][i]))\n\n        # if start position is None, the answer passage has been truncated\n        if start_positions[-1] is None:\n            start_positions[-1] = tokenizer.model_max_length - 1\n        else:\n            start_positions[-1] -= 1\n\n        # if end position is None, the 'char_to_token' function points to the space after the correct token, so add - 1\n        if end_positions[-1] is None:\n            end_positions[-1] = encodings.char_to_token(i, data['answer_end'][i] - 1)\n            # if end position is still None the answer passage has been truncated\n            if end_positions[-1] is None:\n                count += 1\n                end_positions[-1] = tokenizer.model_max_length - 1\n            else:\n                end_positions[-1] -= 1\n        else:\n            end_positions[-1] -= 1\n    # Update the data in dictionary\n    encodings.update({ 'start_positions': torch.tensor(start_positions, device=device), 'end_positions': torch.tensor(end_positions, device=device) })","metadata":{"id":"QkfD_yhNqEXz","execution":{"iopub.status.busy":"2022-06-16T16:25:34.538394Z","iopub.execute_input":"2022-06-16T16:25:34.538915Z","iopub.status.idle":"2022-06-16T16:25:34.547238Z","shell.execute_reply.started":"2022-06-16T16:25:34.538884Z","shell.execute_reply":"2022-06-16T16:25:34.546269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_token_positions(train_tokenizer, train)\nadd_token_positions(valid_tokenizer, valid)\nadd_token_positions(test_tokenizer, test)","metadata":{"id":"cEfvYvk-qGVK","execution":{"iopub.status.busy":"2022-06-16T16:25:34.548667Z","iopub.execute_input":"2022-06-16T16:25:34.549227Z","iopub.status.idle":"2022-06-16T16:25:35.024866Z","shell.execute_reply.started":"2022-06-16T16:25:34.549194Z","shell.execute_reply":"2022-06-16T16:25:35.024133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_tokenizer(tokenizer):\n    del tokenizer['token_type_ids']\n    del tokenizer['attention_mask']","metadata":{"id":"Mb1QnoMzr-kh","execution":{"iopub.status.busy":"2022-06-16T16:25:35.02596Z","iopub.execute_input":"2022-06-16T16:25:35.02635Z","iopub.status.idle":"2022-06-16T16:25:35.030922Z","shell.execute_reply.started":"2022-06-16T16:25:35.026316Z","shell.execute_reply":"2022-06-16T16:25:35.030019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_tokenizer(train_tokenizer)\nclean_tokenizer(valid_tokenizer)\nclean_tokenizer(test_tokenizer)","metadata":{"id":"jHFnPI1MsNUj","execution":{"iopub.status.busy":"2022-06-16T16:25:35.032178Z","iopub.execute_input":"2022-06-16T16:25:35.0325Z","iopub.status.idle":"2022-06-16T16:25:35.047759Z","shell.execute_reply.started":"2022-06-16T16:25:35.032462Z","shell.execute_reply":"2022-06-16T16:25:35.046345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tokenizer","metadata":{"id":"i03awh7nsFp5","outputId":"cf04e57c-54d2-4077-c55b-f6303e17b0f5","execution":{"iopub.status.busy":"2022-06-16T16:25:35.049582Z","iopub.execute_input":"2022-06-16T16:25:35.050375Z","iopub.status.idle":"2022-06-16T16:25:35.067811Z","shell.execute_reply.started":"2022-06-16T16:25:35.050322Z","shell.execute_reply":"2022-06-16T16:25:35.06642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tokenizer.input_ids.shape","metadata":{"id":"SnJgBtbPr3lv","outputId":"037b4927-9bc4-4586-f99b-7ef4b224324e","execution":{"iopub.status.busy":"2022-06-16T16:25:35.069347Z","iopub.execute_input":"2022-06-16T16:25:35.069954Z","iopub.status.idle":"2022-06-16T16:25:35.07754Z","shell.execute_reply.started":"2022-06-16T16:25:35.069908Z","shell.execute_reply":"2022-06-16T16:25:35.076399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SquadDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': torch.tensor(self.encodings['input_ids'], dtype=torch.float32, device=device)[idx].unsqueeze(dim=1),\n            'start_positions': self.encodings['start_positions'][idx],\n            'end_positions': self.encodings['end_positions'][idx],\n        }\n\n    def __len__(self):\n        return len(self.encodings.input_ids)","metadata":{"id":"Y7jW5zdRGA3p","execution":{"iopub.status.busy":"2022-06-16T16:25:35.079021Z","iopub.execute_input":"2022-06-16T16:25:35.08004Z","iopub.status.idle":"2022-06-16T16:25:35.090328Z","shell.execute_reply.started":"2022-06-16T16:25:35.079959Z","shell.execute_reply":"2022-06-16T16:25:35.089221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=64\n\ntrain_dataset = SquadDataset(train_tokenizer)\nval_dataset = SquadDataset(valid_tokenizer)\ntest_dataset = SquadDataset(test_tokenizer)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"id":"FF-lrA4gx8Tg","execution":{"iopub.status.busy":"2022-06-16T16:25:35.092357Z","iopub.execute_input":"2022-06-16T16:25:35.093312Z","iopub.status.idle":"2022-06-16T16:25:35.108356Z","shell.execute_reply.started":"2022-06-16T16:25:35.09326Z","shell.execute_reply":"2022-06-16T16:25:35.107118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model definition","metadata":{"id":"yagcOWuuhNOK"}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"gsQ0h0jwn1tj","execution":{"iopub.status.busy":"2022-06-16T16:25:35.110642Z","iopub.execute_input":"2022-06-16T16:25:35.111462Z","iopub.status.idle":"2022-06-16T16:25:35.117219Z","shell.execute_reply.started":"2022-06-16T16:25:35.111414Z","shell.execute_reply":"2022-06-16T16:25:35.116208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class QABiLSTM(pl.LightningModule):\n    def __init__(self, input_dim, hidden_dim, output_dim, lstm_layers, lstm_dropout, fc_dropout):\n        super().__init__()\n        # LAYER 1: BiLSTM\n        self.lstm = nn.LSTM(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            num_layers=lstm_layers,\n            bidirectional=True,\n            dropout=lstm_dropout if lstm_layers > 1 else 0,\n            batch_first=True\n        )\n\n        # LAYER 2: Fully-connected\n        self.fc_dropout = nn.Dropout(fc_dropout)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # times 2 for bidirectional\n\n        self.init_weights()\n\n    def forward(self, x):\n        # lstm_out = [batch size, sentence length, hidden dim * 2]\n        lstm_out, (hn, cn) = self.lstm(x)\n        # logits = [batch size, sentence length, output dim]\n        logits = self.fc(self.fc_dropout(lstm_out))\n\n        (start, end) = logits.split(1, dim=-1)\n        start = start.squeeze(-1).contiguous()\n        end = end.squeeze(-1).contiguous()\n\n        return start, end\n\n    def init_weights(self):\n        for name, param in self.named_parameters():\n            nn.init.normal_(param.data, mean=0, std=0.1)\n\n    # def init_embeddings(self, word_pad_idx):\n    #     # initialize embedding for padding as zero\n    #     self.embedding.weight.data[word_pad_idx] = torch.zeros(self.embedding_dim)\n\n    def count_parameters(self):\n        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=2),\n                \"monitor\": \"val_loss\",\n                \"frequency\": 2\n            },\n        }\n\n    def step(self, batch):\n        x = batch['input_ids']\n        y_start_idx = batch['start_positions']\n        y_end_idx = batch['end_positions']\n        y_start, y_end = self(x)\n        return y_start, y_end, y_start_idx, y_end_idx\n\n    @staticmethod\n    def compute_loss(y_start, y_end, y_start_idx, y_end_idx):\n        loss1 = F.cross_entropy(y_start, y_start_idx)\n        loss2 = F.cross_entropy(y_end, y_end_idx)\n        return (loss1 + loss2) / 2\n\n\n    def training_step(self, train_batch, batch_idx):\n        torch.cuda.empty_cache()\n        y_start, y_end, y_start_idx, y_end_idx = self.step(train_batch)\n        loss = self.compute_loss(y_start, y_end, y_start_idx, y_end_idx)\n\n        self.log('train_loss', loss)\n        return loss\n    \n    def validation_step(self, val_batch, batch_idx):\n        y_start, y_end, y_start_idx, y_end_idx = self.step(val_batch)\n        loss = self.compute_loss(y_start, y_end, y_start_idx, y_end_idx)\n        \n        self.log('val_loss', loss)\n\n    def test_step(self, test_batch, batch_idx):\n        y_start, y_end, y_start_idx, y_end_idx = self.step(test_batch)\n        loss = self.compute_loss(y_start, y_end, y_start_idx, y_end_idx)\n        \n        self.log('test_loss', loss)","metadata":{"id":"vihvMCAmyrMY","execution":{"iopub.status.busy":"2022-06-16T16:25:35.119048Z","iopub.execute_input":"2022-06-16T16:25:35.120243Z","iopub.status.idle":"2022-06-16T16:25:35.140903Z","shell.execute_reply.started":"2022-06-16T16:25:35.120191Z","shell.execute_reply":"2022-06-16T16:25:35.140096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = QABiLSTM(\n    input_dim=1,\n    hidden_dim=64,\n    output_dim=2,\n    lstm_layers=1,\n    lstm_dropout=0.1,\n    fc_dropout=0.25,\n)","metadata":{"id":"ypM5NYpLluNV","execution":{"iopub.status.busy":"2022-06-16T16:25:35.14225Z","iopub.execute_input":"2022-06-16T16:25:35.143306Z","iopub.status.idle":"2022-06-16T16:25:35.22105Z","shell.execute_reply.started":"2022-06-16T16:25:35.143257Z","shell.execute_reply":"2022-06-16T16:25:35.220257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.count_parameters()","metadata":{"id":"BnWtSWjRM5LA","outputId":"95b2bd18-edb8-4f8b-c49f-2b2aadaba01c","execution":{"iopub.status.busy":"2022-06-16T16:25:35.222351Z","iopub.execute_input":"2022-06-16T16:25:35.222941Z","iopub.status.idle":"2022-06-16T16:25:35.228796Z","shell.execute_reply.started":"2022-06-16T16:25:35.222903Z","shell.execute_reply":"2022-06-16T16:25:35.227932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"AMg3Q1VumZqf"}},{"cell_type":"code","source":"# training\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", every_n_train_steps=100)\ntrainer = pl.Trainer(max_epochs=100, gpus=1, precision=16, log_every_n_steps=10, callbacks=[EarlyStopping(monitor=\"val_loss\"), checkpoint_callback])\ntrainer.fit(model, train_loader, val_loader, ckpt_path='../input/modell/epoch5-step6200.ckpt')","metadata":{"id":"YZsX2eZpmblS","outputId":"619d0845-1577-42b7-8132-9e858df8de81","execution":{"iopub.status.busy":"2022-06-16T16:25:35.230253Z","iopub.execute_input":"2022-06-16T16:25:35.23104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), './final_BiLSTM.pt')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"trainer.test(model, dataloaders=test_loader)","metadata":{"id":"kyNk963FhZeA","trusted":true},"execution_count":null,"outputs":[]}]}